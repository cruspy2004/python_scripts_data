{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fec0ab78",
   "metadata": {},
   "source": [
    "# Lab 10: K-Nearest Neighbors (KNN) Classifier\n",
    "\n",
    "**Student Name:** Muhammad Haadhee Sheeraz Mian  \n",
    "**Reg No:** 478359\n",
    "\n",
    "This notebook implements the K-Nearest Neighbors algorithm following the lab manual."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe68d3d1",
   "metadata": {},
   "source": [
    "## 3) Preprocessing in Code\n",
    "### Dimensionality Reduction (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f06085e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "\n",
    "# Sample Data\n",
    "data = {\n",
    "    'Age': [25, 35, 45, 55, 40, 60],\n",
    "    'Income': [35000, 70000, 90000, 120000, 45000, 100000]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Step 1: Feature Scaling\n",
    "scaler = StandardScaler()  # Alternatively, use MinMaxScaler()\n",
    "df_scaled = scaler.fit_transform(df)\n",
    "\n",
    "# Step 2: Dimensionality Reduction (Optional)\n",
    "pca = PCA(n_components=2)\n",
    "df_reduced = pca.fit_transform(df_scaled)\n",
    "\n",
    "print(\"Scaled Data:\\n\", df_scaled)\n",
    "print(\"\\nReduced Data:\\n\", df_reduced)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b15f954",
   "metadata": {},
   "source": [
    "## 4) Implementing KNN from Scratch\n",
    "### Step 1 – Calculate Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac6d92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# Function to calculate Euclidean distance\n",
    "def euclidean_distance(point1, point2):\n",
    "    return math.sqrt(sum((p1 - p2) ** 2 for p1, p2 in zip(point1, point2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a65bd5",
   "metadata": {},
   "source": [
    "### Step 2 – Find the K Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c66448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find k nearest neighbors\n",
    "def get_k_nearest_neighbors(training_data, new_point, k):\n",
    "    distances = []\n",
    "    \n",
    "    # Calculate distance from new_point to each point in the training_data\n",
    "    for data_point in training_data:\n",
    "        distance = euclidean_distance(new_point[:-1], data_point[:-1])  # Ignore labels\n",
    "        distances.append((distance, data_point))\n",
    "    \n",
    "    # Sort by distance and select the k closest points\n",
    "    distances.sort(key=lambda x: x[0])\n",
    "    neighbors = [data[1] for data in distances[:k]]\n",
    "    return neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de18996",
   "metadata": {},
   "source": [
    "### Step 3 – Make the Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c13d34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Function to predict class label based on k nearest neighbors\n",
    "def predict_classification(training_data, new_point, k):\n",
    "    neighbors = get_k_nearest_neighbors(training_data, new_point, k)\n",
    "    \n",
    "    # Extract labels and find the most common class among neighbors\n",
    "    labels = [neighbor[-1] for neighbor in neighbors]\n",
    "    most_common = Counter(labels).most_common(1)\n",
    "    return most_common[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4dbf595",
   "metadata": {},
   "source": [
    "### Full KNN Function for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42475624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full KNN Function for Classification\n",
    "def knn_classify(training_data, new_point, k):\n",
    "    # Step 1: Get the k nearest neighbors\n",
    "    neighbors = get_k_nearest_neighbors(training_data, new_point, k)\n",
    "    \n",
    "    # Step 2: Predict the most common class among neighbors\n",
    "    labels = [neighbor[-1] for neighbor in neighbors]\n",
    "    prediction = Counter(labels).most_common(1)[0][0]\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085e7924",
   "metadata": {},
   "source": [
    "## 5) Using Scikit-Learn for KNN\n",
    "### Loading a Sample Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e656e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "data = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "data['target'] = iris.target\n",
    "data['target'] = data['target'].map({0: 'Setosa', 1: 'Versicolor', 2: 'Virginica'})\n",
    "\n",
    "# Display first few rows\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9011e78c",
   "metadata": {},
   "source": [
    "### Preprocessing Data with Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37d91a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the feature data\n",
    "scaled_features = scaler.fit_transform(iris.data)\n",
    "\n",
    "# Now scaled_features is ready for KNN\n",
    "print(\"Scaled Features shape:\", scaled_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79cbce9",
   "metadata": {},
   "source": [
    "### Implementing KNN with Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351cdb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_features, iris.target, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize the KNN classifier with k=3\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# Fit the model\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "print(\"Model trained successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d7c0d0",
   "metadata": {},
   "source": [
    "### Making Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f212612a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the test set\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Display predictions\n",
    "print(\"Predicted labels:\", y_pred)\n",
    "print(\"Actual labels:   \", y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14f25e1",
   "metadata": {},
   "source": [
    "### Evaluating Model Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6a81fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb613f7",
   "metadata": {},
   "source": [
    "### Visualizing the Decision Boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a584df5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Select only petal length and petal width for simplicity\n",
    "X = iris.data[:, 2:4]\n",
    "y = iris.target\n",
    "\n",
    "# Fit KNN model on the simplified dataset\n",
    "knn_2d = KNeighborsClassifier(n_neighbors=3)\n",
    "knn_2d.fit(X, y)\n",
    "\n",
    "# Create a mesh grid for plotting\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.02),\n",
    "                     np.arange(y_min, y_max, 0.02))\n",
    "\n",
    "# Predict classes for each point in the mesh grid\n",
    "Z = knn_2d.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "# Plot decision boundary and data points\n",
    "plt.contourf(xx, yy, Z, alpha=0.3, cmap=plt.cm.coolwarm)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, edgecolor='k', cmap=plt.cm.coolwarm)\n",
    "plt.xlabel('Petal length')\n",
    "plt.ylabel('Petal width')\n",
    "plt.title(\"Decision Boundary of KNN Classifier\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d059f4e2",
   "metadata": {},
   "source": [
    "## 6) Hyperparameter Tuning\n",
    "### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c59331c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Define the model\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    'n_neighbors': [1, 3, 5, 7, 9],\n",
    "    'weights': ['uniform', 'distance']\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV with the parameter grid and cross-validation\n",
    "grid_search = GridSearchCV(knn, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit the grid search on the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters found\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(f\"Best cross-validation score: {grid_search.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ebc9fd",
   "metadata": {},
   "source": [
    "### Randomized Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6109868c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "# Define the parameter distribution\n",
    "param_dist = {\n",
    "    'n_neighbors': randint(1, 20),  # Random integer between 1 and 20\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan']\n",
    "}\n",
    "\n",
    "# Initialize RandomizedSearchCV with 100 iterations\n",
    "random_search = RandomizedSearchCV(knn, param_distributions=param_dist, n_iter=100, cv=5, scoring='accuracy', random_state=42)\n",
    "\n",
    "# Fit the randomized search on the training data\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters found\n",
    "print(\"Best parameters:\", random_search.best_params_)\n",
    "print(f\"Best cross-validation score: {random_search.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375f417c",
   "metadata": {},
   "source": [
    "## 7) Mini Challenge\n",
    "### Iris Dataset Classification with KNN\n",
    "\n",
    "**Task Overview:**\n",
    "- Classify flowers into three species: Setosa, Versicolor, and Virginica\n",
    "- Preprocess the data\n",
    "- Implement KNN model\n",
    "- Perform hyperparameter tuning with Grid Search\n",
    "- Visualize results\n",
    "- **Bonus:** Apply PCA for dimensionality reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20619ddc",
   "metadata": {},
   "source": [
    "### Step 1: Load and Explore the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fa9e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Create DataFrame for visualization\n",
    "df_iris = pd.DataFrame(X, columns=iris.feature_names)\n",
    "df_iris['species'] = pd.Categorical.from_codes(y, iris.target_names)\n",
    "\n",
    "print(\"Dataset Shape:\", df_iris.shape)\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(df_iris.head())\n",
    "print(\"\\nDataset Description:\")\n",
    "print(df_iris.describe())\n",
    "print(\"\\nClass Distribution:\")\n",
    "print(df_iris['species'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1dbe7c7",
   "metadata": {},
   "source": [
    "### Step 2: Visualize the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf9e735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pairplot\n",
    "sns.pairplot(df_iris, hue='species', height=2.5)\n",
    "plt.suptitle('Iris Dataset Pairplot', y=1.02)\n",
    "plt.show()\n",
    "\n",
    "# Correlation heatmap\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(df_iris.iloc[:, :-1].corr(), annot=True, cmap='coolwarm', center=0)\n",
    "plt.title('Feature Correlation Heatmap')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78cc144c",
   "metadata": {},
   "source": [
    "### Step 3: Preprocess the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2072f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Split the dataset (80-20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"Training set size:\", X_train.shape[0])\n",
    "print(\"Testing set size:\", X_test.shape[0])\n",
    "print(\"\\nFeatures scaled successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646c03bb",
   "metadata": {},
   "source": [
    "### Step 4: Implement KNN and Test Different K Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c962a585",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import numpy as np\n",
    "\n",
    "# Test different values of K\n",
    "k_values = range(1, 31)\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "\n",
    "for k in k_values:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    train_scores.append(knn.score(X_train_scaled, y_train))\n",
    "    test_scores.append(knn.score(X_test_scaled, y_test))\n",
    "\n",
    "# Find the best K\n",
    "best_k = k_values[np.argmax(test_scores)]\n",
    "print(f\"Best K value: {best_k}\")\n",
    "print(f\"Best test accuracy: {max(test_scores):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466d447e",
   "metadata": {},
   "source": [
    "### Step 5: Visualize Accuracy vs K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff12897c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and testing accuracy\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(k_values, train_scores, 'bo-', label='Training Accuracy', linewidth=2)\n",
    "plt.plot(k_values, test_scores, 'rs-', label='Testing Accuracy', linewidth=2)\n",
    "plt.axvline(x=best_k, color='green', linestyle='--', label=f'Best K={best_k}')\n",
    "plt.xlabel('Number of Neighbors (K)', fontsize=12)\n",
    "plt.ylabel('Accuracy', fontsize=12)\n",
    "plt.title('KNN Accuracy vs K Value', fontsize=14, fontweight='bold')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1d494e",
   "metadata": {},
   "source": [
    "### Step 6: Train Final Model and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5636230",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Train final model with best K\n",
    "knn_final = KNeighborsClassifier(n_neighbors=best_k)\n",
    "knn_final.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = knn_final.predict(X_test_scaled)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Final Model Accuracy: {accuracy:.4f}\")\n",
    "print(f\"\\nClassification Report:\\n\")\n",
    "print(classification_report(y_test, y_pred, target_names=iris.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ecccf2c",
   "metadata": {},
   "source": [
    "### Step 7: Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60470799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and visualize confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=iris.target_names,\n",
    "            yticklabels=iris.target_names)\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title(f'Confusion Matrix (K={best_k})')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d62366",
   "metadata": {},
   "source": [
    "### Step 8: Hyperparameter Tuning with Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f565c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    'n_neighbors': range(1, 31),\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan', 'minkowski']\n",
    "}\n",
    "\n",
    "# Perform Grid Search\n",
    "grid_search = GridSearchCV(KNeighborsClassifier(), param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(f\"Best Cross-Validation Score: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# Test the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred_best = best_model.predict(X_test_scaled)\n",
    "best_accuracy = accuracy_score(y_test, y_pred_best)\n",
    "print(f\"Test Accuracy with Best Parameters: {best_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f636e0a6",
   "metadata": {},
   "source": [
    "### Step 9: Visualize Decision Boundaries (2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2aed3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use only 2 features for visualization\n",
    "X_2d = X[:, [2, 3]]  # Petal length and petal width\n",
    "X_train_2d, X_test_2d, y_train_2d, y_test_2d = train_test_split(X_2d, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Scale 2D features\n",
    "scaler_2d = StandardScaler()\n",
    "X_train_2d_scaled = scaler_2d.fit_transform(X_train_2d)\n",
    "X_test_2d_scaled = scaler_2d.transform(X_test_2d)\n",
    "\n",
    "# Train KNN on 2D data\n",
    "knn_2d = KNeighborsClassifier(n_neighbors=best_k)\n",
    "knn_2d.fit(X_train_2d_scaled, y_train_2d)\n",
    "\n",
    "# Create mesh grid\n",
    "h = 0.02\n",
    "x_min, x_max = X_train_2d_scaled[:, 0].min() - 1, X_train_2d_scaled[:, 0].max() + 1\n",
    "y_min, y_max = X_train_2d_scaled[:, 1].min() - 1, X_train_2d_scaled[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "\n",
    "# Predict on mesh\n",
    "Z = knn_2d.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "# Plot decision boundary\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.contourf(xx, yy, Z, alpha=0.4, cmap='viridis')\n",
    "scatter = plt.scatter(X_train_2d_scaled[:, 0], X_train_2d_scaled[:, 1],\n",
    "                     c=y_train_2d, cmap='viridis', edgecolors='black', s=50)\n",
    "plt.xlabel('Petal Length (scaled)')\n",
    "plt.ylabel('Petal Width (scaled)')\n",
    "plt.title(f'KNN Decision Boundary (K={best_k})')\n",
    "plt.colorbar(scatter)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"2D Model Accuracy: {knn_2d.score(X_test_2d_scaled, y_test_2d):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c7f0ec",
   "metadata": {},
   "source": [
    "### BONUS: Apply PCA for Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d788196",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Apply PCA to reduce to 2 components\n",
    "pca = PCA(n_components=2)\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "print(f\"Explained variance ratio: {pca.explained_variance_ratio_}\")\n",
    "print(f\"Total variance explained: {sum(pca.explained_variance_ratio_):.4f}\")\n",
    "\n",
    "# Train KNN on PCA-reduced data\n",
    "knn_pca = KNeighborsClassifier(n_neighbors=best_k)\n",
    "knn_pca.fit(X_train_pca, y_train)\n",
    "\n",
    "# Evaluate PCA model\n",
    "y_pred_pca = knn_pca.predict(X_test_pca)\n",
    "accuracy_pca = accuracy_score(y_test, y_pred_pca)\n",
    "\n",
    "print(f\"\\nAccuracy WITHOUT PCA: {accuracy:.4f}\")\n",
    "print(f\"Accuracy WITH PCA: {accuracy_pca:.4f}\")\n",
    "print(f\"\\nClassification Report (PCA):\\n\")\n",
    "print(classification_report(y_test, y_pred_pca, target_names=iris.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7750e7",
   "metadata": {},
   "source": [
    "### Visualize PCA Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ad991e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot PCA decision boundary\n",
    "h = 0.02\n",
    "x_min, x_max = X_train_pca[:, 0].min() - 1, X_train_pca[:, 0].max() + 1\n",
    "y_min, y_max = X_train_pca[:, 1].min() - 1, X_train_pca[:, 1].max() + 1\n",
    "xx_pca, yy_pca = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "\n",
    "Z_pca = knn_pca.predict(np.c_[xx_pca.ravel(), yy_pca.ravel()])\n",
    "Z_pca = Z_pca.reshape(xx_pca.shape)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.contourf(xx_pca, yy_pca, Z_pca, alpha=0.4, cmap='viridis')\n",
    "scatter = plt.scatter(X_train_pca[:, 0], X_train_pca[:, 1],\n",
    "                     c=y_train, cmap='viridis', edgecolors='black', s=50)\n",
    "plt.xlabel('First Principal Component')\n",
    "plt.ylabel('Second Principal Component')\n",
    "plt.title(f'KNN Decision Boundary with PCA (K={best_k})')\n",
    "plt.colorbar(scatter)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.4)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
